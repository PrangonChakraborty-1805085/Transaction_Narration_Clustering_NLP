{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df15a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8592957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e968577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0f8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e5adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669c6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76db5bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= pd.read_csv(\"./preprocessed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bb158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['PROCESSED_NARATION'] = data['STOP_WORD_REMOVED_NARATION'].str.replace('[^\\w\\s]', '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b825c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "narations = data['STOP_WORD_REMOVED_NARATION'].dropna().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1af6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def str_to_list(words):\n",
    "#     return words.split(' ')\n",
    "\n",
    "# narations_modified = narations.apply(str_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a46efa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e17059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(smooth_idf=True, use_idf=True, min_df = 5)\n",
    "vectorizer.fit_transform(narations)\n",
    "\n",
    "# using get_feature_names_out instead of get_feature_names\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22bfe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_n_from_top_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature, score\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def sort_coo_matrix(coo_matrix):\n",
    "    \"\"\"----This function sorts a dict with highest score----\"\"\"\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def keywords(vectorizer, feature_names, doc, k=10):\n",
    "    \"\"\"--This method returns top k keywords from a doc using TF-IDF method--\"\"\"\n",
    "\n",
    "    #generate tf-idf for the given document\n",
    "    tf_idf_vector = vectorizer.transform([doc])\n",
    "    \n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo_matrix(tf_idf_vector.tocoo())\n",
    "\n",
    "    #extract only TOP_K_KEYWORDS\n",
    "    keywords=extract_n_from_top_from_vector(feature_names,sorted_items,k)\n",
    "    \n",
    "    return list(keywords.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c56605",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_K_KEYWORDS = 10\n",
    "result = []\n",
    "for sentence in narations:\n",
    "    dataframe = {}\n",
    "    dataframe['PROCESSED_NARATION_FINAL'] = sentence\n",
    "    dataframe['TOP_KEYWORDS'] = keywords(vectorizer, feature_names, sentence, TOP_K_KEYWORDS)\n",
    "    result.append(dataframe)\n",
    "final_data = pd.DataFrame(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f426c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "final_data['TOP_KEYWORDS'] = final_data['PROCESSED_NARATION_FINAL']\n",
    "model = Word2Vec(final_data['TOP_KEYWORDS'], min_count=1, vector_size = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ac19a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2vec_mean_calc(text, model, vector_size=150):\n",
    "    summ = np.zeros(vector_size)\n",
    "    cnt = 1\n",
    "    for word in text:\n",
    "        summ+=model.wv[word]\n",
    "        cnt+=1\n",
    "    return summ/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2106d238",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['AVG_VECT'] = final_data['TOP_KEYWORDS'].apply(lambda text : word2vec_mean_calc(text,model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd60629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kmeans clustering\n",
    "wcss = []\n",
    "for i in range(7,15):\n",
    "    kmeans = KMeans(i, init = 'k-means++', max_iter = 500,n_init = 10, random_state = 0)\n",
    "    kmeans.fit(list(final_data['AVG_VECT']))\n",
    "    wcss.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4716669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting graph\n",
    "\n",
    "plt.plot(range(7,15), wcss)\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab094b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We got best value 15, now applying 15\n",
    "\n",
    "kmeans = KMeans(n_clusters = 15, init = 'k-means++', max_iter = 500, n_init=10, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa6f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['KMEANS_CLUSTER'] = kmeans.fit_predict(list(final_data['AVG_VECT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f92d677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determining value of eps for dbscan\n",
    "neighbors = NearestNeighbors(n_neighbors=20)\n",
    "neighbors_fit = neighbors.fit(list(final_data['AVG_VECT']))\n",
    "distances, indices = neighbors_fit.kneighbors(list(final_data['AVG_VECT']))\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]\n",
    "plt.plot(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a87fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.9, min_samples=300).fit(list(final_data['AVG_VECT']))\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "n_noise_ = list(labels).count(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4811d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['DBSCAN_CLUSTER']  = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e23c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = MiniBatchKMeans(n_clusters=12, random_state=0, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160e8d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data[\"MINIBATCH_CLUSTER\"] = kmeans.fit_predict(list(final_data['AVG_VECT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd65b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the final data to excel sheet\n",
    "final_data.to_excel('final_result.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab01d050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
